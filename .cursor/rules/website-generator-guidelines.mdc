---
description: "Project guidance and development practices for Docker-first application development"
globs: ["**/*"]
alwaysApply: true
---

# Docker-First Project Guidelines

> **📋 About This Document:** This is the Cursor project rule that automatically gets added as context to every AI prompt in this workspace in Cursor (YOU). It provides essential guidance about the project's architecture, development practices, and constraints that must be followed when generating or modifying code.

## 🚀 Single-Command Docker Setup

This project is designed for **zero-configuration deployment**. Everything works out of the box with a single command.

### 🎯 Core Architecture:
- **All services run in Docker containers** - no local runtime dependencies needed
- **All dependencies managed inside containers** - package installation happens in Docker
- **No lock files in git** - Docker generates dependencies fresh every time
- **Servers bind to `0.0.0.0`** - proper container networking
- **Applications optimized for Docker** - polling enabled, hot reload configured appropriately

### 🚀 First-Time Setup:

**Clone and run - that's it:**
```bash
git clone <repo-url>
cd <project-name>
docker-compose up --build -d
```

No additional setup, no dependency management, no configuration needed.

### 🔄 Development Workflow:

```bash
# First, ensure Docker daemon is running:
docker info > /dev/null 2>&1 || { echo "Docker daemon not running. Please start Docker Desktop."; exit 1; }

# When asked to "run the project":
docker-compose up --build -d

# Check readiness with health checks:
curl -s http://localhost:8000/health

# Automatically open browser:
open http://localhost:8000  # macOS
# or xdg-open http://localhost:8000  # Linux
```

**Why this workflow:**
- ✅ **Docker daemon check first** - prevents cryptic errors if Docker daemon isn't running
- ✅ **Terminal returns control** - can continue with next steps
- ✅ **Programmatic health checks** - verify readiness
- ✅ **Automatic browser opening** - seamless user experience
- ✅ **Clean task completion** - clear start/finish workflow

### 📦 Adding Dependencies:
```bash
# Add dependencies inside containers:
docker-compose run --rm --no-deps <service-name> <package-manager> install <package>

# Then rebuild and restart:
docker-compose up --build -d
```

### 🎯 What's Gitignored (Docker-Managed):
- `node_modules/` / `venv/` / similar - Generated inside containers
- Package lock files - Generated fresh on each build
- Build artifacts - Dynamically generated files
- Temporary files - Runtime-generated content

### 🎯 Design Philosophy:

**"Clone and Run"** - No local setup, no dependency hell, no configuration. Just Docker.

### 📖 Documentation Policy:

**This project has NO README file** - and none should be created.

**Why no README:**
- ✅ **This project guidelines file IS the complete documentation**
- ✅ **Automatically accessible in Cursor** - always available as context
- ✅ **Self-maintaining** - updates with the project through AI assistance
- ✅ **Rich formatting** - better than traditional README files
- ✅ **Always current** - living document that evolves with the codebase

**🚨 ABSOLUTE RULE for AI Assistants:**
- **NEVER create README.md, readme.txt, or any standalone documentation files**
- **ALL documentation belongs in this project guidelines file**
- **Refer users to this file for ALL project information**

### 🔑 Environment Configuration Rules

**CRITICAL:** Environment file handling follows strict security protocols:

- **`env.template`** - Template file showing required environment variables (safe for git, Cursor accessible)
- **`.env`** - Actual environment file with real secrets (gitignored, Cursor-ignored, user-managed)

**🚨 ABSOLUTE RULES for AI Assistants:**
1. **NEVER create or recreate the `.env` file** - it exists and is user-managed
2. **TRUST that `.env` exists** - even though Cursor can't see it due to security blocking
3. **ASSUME `.env` contains the same structure as `env.template`** but with actual values filled in
4. **ONLY modify `env.template`** when environment variable changes are needed
5. **ALWAYS refer users to copy `env.template` to `.env`** for initial setup

**Why this setup:**
- ✅ **Security:** Real secrets never visible to AI or git
- ✅ **Functionality:** Docker and applications can access `.env` normally  
- ✅ **Template:** `env.template` shows structure without exposing secrets
- ✅ **Standard:** Follows industry-standard environment file practices

## 🌐 Website Generator Application

Full-stack application that scrapes websites and generates modern, optimized versions using AI.

### Architecture:
- **Frontend**: Clean web interface for URL input and result viewing
- **Backend**: FastAPI service handling scraping, AI processing, and storage
- **Database**: PostgreSQL instance for persistence and job tracking
- **AI Processing**: OpenAI GPT integration for HTML/CSS/JS generation

### Usage:
```bash
# Start the application:
docker-compose up --build -d

# Access web interface:
open http://localhost:8000

# Check system health:
curl -s http://localhost:8000/health
```

### Core Features:
1. **Web Interface**: Responsive UI with URL input and real-time status
2. **Async Processing**: Background job queue with progress tracking
3. **AI Generation**: GPT-powered modern website creation
4. **Persistent Storage**: Database persistence for sharing and archival
5. **Smart Identifiers**: Intelligent URL-to-identifier extraction
6. **Secure Viewing**: Sandboxed iframe display of generated websites

### API Endpoints:
- `GET /` - Web interface
- `POST /generate` - Start website generation
- `GET /status/{job_id}` - Check processing status  
- `GET /website/{identifier}` - View generated website
- `GET /health` - Service health check

### Development:
```bash
# View logs:
docker-compose logs -f backend

# Database access:
docker-compose exec postgres psql -U postgres -d website_generator

# Add dependencies:
docker-compose run --rm --no-deps backend pip install <package>
docker-compose up --build -d
```