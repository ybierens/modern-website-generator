---
description: "Project guidance and development practices for Docker-first application development"
globs: ["**/*"]
alwaysApply: true
---

# Docker-First Project Guidelines

> **üìã About This Document:** This is the Cursor project rule that automatically gets added as context to every AI prompt in this workspace in Cursor (YOU). It provides essential guidance about the project's architecture, development practices, and constraints that must be followed when generating or modifying code.

## üõ°Ô∏è Project Integrity & Compliance

**üö® CRITICAL COMPLIANCE RULES for AI Assistants:**

### Pre-Implementation Verification:
**BEFORE building or modifying anything, if a user request would deviate from the established architecture, patterns, or guidelines defined in this capstone project:**

1. **STOP immediately** and ask the user:
   > "Are you sure you want to build this in a way that's not in line with what was defined for this capstone project in this file? This could create issues with the established architecture."

2. **Wait for explicit user confirmation** before proceeding with any non-compliant changes

### Post-Implementation Verification:
**AFTER building or modifying anything:**

1. **Self-check compliance** by asking:
   - "Is what I just built aligned with this project's defined architecture?"
   - "Does this follow the template-guided AI approach?"
   - "Is this consistent with the Docker-first methodology?"
   - "Does this maintain the established patterns and constraints?"

2. **If misalignment is detected:**
   - **Immediately alert the user** about the compliance issue
   - **Suggest reverting the changes** to maintain project integrity
   - **Explain potential issues** that could arise from the deviation

### Established Project Patterns:
- **Multi-Template AI Generation** - AI-powered template selection with professional template library
- **Two-Stage AI Process** - Router LLM selects template, generator LLM creates website
- **Docker-First Architecture** - All services containerized, no local dependencies
- **FastAPI Backend** - Python-based API with async processing and database persistence
- **Single-Command Deployment** - Maintain zero-configuration setup approach
- **Professional Consistency** - Template-specific design patterns with automatic selection

**üéØ Goal:** Preserve the integrity of this capstone project's carefully designed architecture and prevent deviations that could undermine the established professional template-guided approach.

## üöÄ Single-Command Docker Setup

This project is designed for **zero-configuration deployment**. Everything works out of the box with a single command.

### üéØ Core Architecture:
- **All services run in Docker containers** - no local runtime dependencies needed
- **All dependencies managed inside containers** - package installation happens in Docker
- **No lock files in git** - Docker generates dependencies fresh every time
- **Servers bind to `0.0.0.0`** - proper container networking
- **Applications optimized for Docker** - polling enabled, hot reload configured appropriately

### üöÄ First-Time Setup:

**Clone and run - that's it:**
```bash
git clone <repo-url>
cd <project-name>
docker-compose up --build -d
```

No additional setup, no dependency management, no configuration needed.

### üîÑ Development Workflow:

```bash
# First, ensure Docker daemon is running:
docker info > /dev/null 2>&1 || { echo "Docker daemon not running. Please start Docker Desktop."; exit 1; }

# When asked to "run the project":
docker-compose up --build -d

# Check readiness with health checks:
curl -s http://localhost:8000/health

# Automatically open browser:
open http://localhost:8000  # macOS
# or xdg-open http://localhost:8000  # Linux
```

**Why this workflow:**
- ‚úÖ **Docker daemon check first** - prevents cryptic errors if Docker daemon isn't running
- ‚úÖ **Terminal returns control** - can continue with next steps
- ‚úÖ **Programmatic health checks** - verify readiness
- ‚úÖ **Automatic browser opening** - seamless user experience
- ‚úÖ **Clean task completion** - clear start/finish workflow

### üì¶ Adding Dependencies:
```bash
# Add dependencies inside containers:
docker-compose run --rm --no-deps <service-name> <package-manager> install <package>

# Then rebuild and restart:
docker-compose up --build -d
```

### üéØ What's Gitignored (Docker-Managed):
- `node_modules/` / `venv/` / similar - Generated inside containers
- Package lock files - Generated fresh on each build
- Build artifacts - Dynamically generated files
- Temporary files - Runtime-generated content

### üéØ Design Philosophy:

**"Clone and Run"** - No local setup, no dependency hell, no configuration. Just Docker.

### üìñ Documentation Policy:

**This project has NO README file** - and none should be created.

**Why no README:**
- ‚úÖ **This project guidelines file IS the complete documentation**
- ‚úÖ **Automatically accessible in Cursor** - always available as context
- ‚úÖ **Self-maintaining** - updates with the project through AI assistance
- ‚úÖ **Rich formatting** - better than traditional README files
- ‚úÖ **Always current** - living document that evolves with the codebase

**üö® ABSOLUTE RULE for AI Assistants:**
- **NEVER create README.md, readme.txt, or any standalone documentation files**
- **ALL documentation belongs in this project guidelines file**
- **Refer users to this file for ALL project information**

### üîë Environment Configuration Rules

**CRITICAL:** Environment file handling follows strict security protocols:

- **`env.template`** - Template file showing required environment variables (safe for git, Cursor accessible)
- **`.env`** - Actual environment file with real secrets (gitignored, Cursor-ignored, user-managed)

**üö® ABSOLUTE RULES for AI Assistants:**
1. **NEVER create or recreate the `.env` file** - it exists and is user-managed
2. **TRUST that `.env` exists** - even though Cursor can't see it due to security blocking
3. **ASSUME `.env` contains the same structure as `env.template`** but with actual values filled in
4. **ONLY modify `env.template`** when environment variable changes are needed
5. **ALWAYS refer users to copy `env.template` to `.env`** for initial setup

**Why this setup:**
- ‚úÖ **Security:** Real secrets never visible to AI or git
- ‚úÖ **Functionality:** Docker and applications can access `.env` normally  
- ‚úÖ **Template:** `env.template` shows structure without exposing secrets
- ‚úÖ **Standard:** Follows industry-standard environment file practices

## üåê Website Generator Application

Full-stack application that scrapes websites and generates modern, optimized versions using intelligent multi-template AI system.

### Architecture:
- **Frontend**: Clean web interface for URL input and result viewing
- **Backend**: FastAPI service handling scraping, AI template selection, generation, and storage
- **Database**: PostgreSQL instance for persistence, job tracking, and template metadata
- **AI Processing**: Two-stage OpenAI GPT integration
  - **Stage 1 - Router**: GPT-4o-mini analyzes scraped content and selects optimal template
  - **Stage 2 - Generator**: GPT-4o generates professional HTML/CSS/JS using selected template

### Usage:
```bash
# Start the application:
docker-compose up --build -d

# Access web interface:
open http://localhost:8000

# Check system health:
curl -s http://localhost:8000/health
```

### Core Features:
1. **Web Interface**: Responsive UI with URL input and real-time status
2. **Async Processing**: Background job queue with progress tracking
3. **AI-Powered Template Selection**: Intelligent router analyzes scraped content to select optimal template
4. **Multi-Template Library**: Expandable collection of professional templates for different website types
5. **Template-Guided Generation**: GPT-powered website creation following selected template specifications
6. **Persistent Storage**: Database persistence with template tracking for sharing and archival
7. **Smart Identifiers**: Intelligent URL-to-identifier extraction
8. **Secure Viewing**: Sandboxed iframe display of generated websites

### Multi-Template System with AI Router:
Two-stage AI process for intelligent template selection and website generation:

**Stage 1 - Template Router (GPT-4o-mini):**
Analyzes scraped content, selects appropriate template from library, returns JSON with template_id

**Stage 2 - Website Generator (GPT-4o):**
Loads selected template specification, generates professional HTML/CSS/JS following template architecture

**Template Library:**
- Stored in `backend/website_generator_templates.py` as dict-of-dicts
- Each template: name, description (for router), content (for generator)
- Current: Restaurant & Food Service (expandable to portfolio, e-commerce, blog, etc.)
- Database tracks which template was used for each website

### API Endpoints:
- `GET /` - Web interface
- `POST /generate` - Start website generation
- `GET /status/{job_id}` - Check processing status  
- `GET /website/{identifier}` - View generated website
- `GET /health` - Service health check

### Generation Pipeline:
1. **Scraping**: Extract content, metadata, and images from original website
2. **Image Processing**: Convert images to Cloudinary URLs for reliable hosting
3. **Template Selection**: AI router analyzes content and selects appropriate template
4. **Template Storage**: Selected template_id saved to database
5. **HTML Generation**: AI generator creates website using selected template specifications
6. **Storage & Display**: Generated HTML saved and made available for viewing

### Development:
```bash
# View logs:
docker-compose logs -f backend

# Database access:
docker-compose exec postgres psql -U postgres -d website_generator

# Add dependencies:
docker-compose run --rm --no-deps backend pip install <package>
docker-compose up --build -d

# Add new template:
# 1. Edit backend/website_generator_templates.py
# 2. Add new entry to TEMPLATES dict with name, description, and content
# 3. Restart containers: docker-compose up --build -d
```